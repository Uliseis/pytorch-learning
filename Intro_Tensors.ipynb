{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "decefed7",
   "metadata": {},
   "source": [
    "# PyTorch introduction: Tensors (Chapter 3)\n",
    "\n",
    "# Constructing our first tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eb2f4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38677ab2",
   "metadata": {},
   "source": [
    "#### We will create a one dimensional tensor of size 3 filled with 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfed2cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "465be39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0632b6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb18bcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 2.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2] = 2.0\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dc351a",
   "metadata": {},
   "source": [
    "#### Now let's store a list of coordinates of a triangle. We will store Xs in the even and Ys in the odd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2fdf0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.zeros(6)\n",
    "\n",
    "points[0] = 4.0\n",
    "points[1] = 1.0\n",
    "points[2] = 5.0\n",
    "points[3] = 3.0\n",
    "points[4] = 2.0\n",
    "points[5] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5127bb3",
   "metadata": {},
   "source": [
    "#### We can also do it like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f61420fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1., 5., 3., 2., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([4.0, 1.0, 5.0, 3.0, 2.0, 1.0])\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf83dd6",
   "metadata": {},
   "source": [
    "#### Coordinates of the first points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "783a796a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0, 1.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(points[0]), float(points[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2873fb",
   "metadata": {},
   "source": [
    "#### It's better to use a 2D tensor for this purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00d5f214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12bae34",
   "metadata": {},
   "source": [
    "#### Let's ask for it's shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "434ddbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b8ec1a",
   "metadata": {},
   "source": [
    "#### We can create a tensor with the desired shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cdbc45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.zeros(3,2)\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59c8f37",
   "metadata": {},
   "source": [
    "#### We can access an individual element using two indices. We will return the Y-coord of the first element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "129d7621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "\n",
    "points[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1800e7f",
   "metadata": {},
   "source": [
    "#### We can acces multiple elements and choosing which of them we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2474b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 1.],\n",
       "         [5., 3.],\n",
       "         [2., 1.]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1:] # All rows after the first, implicitly all columns\n",
    "points[1:, :] # All rows after the first; all columns\n",
    "points[1:, 0] # All rows after the first; first column\n",
    "points[None] # Adds a dimension of size 1, just like unsqueeze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add5847d",
   "metadata": {},
   "source": [
    "## Named Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d305a2dc",
   "metadata": {},
   "source": [
    "#### We want to turn an image into gray scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cf3e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t = torch.randn(3, 5, 5) # shape [channels, rows, columns]\n",
    "weights = torch.tensor([0.2126, 0.7152, 0.0722])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f905d2",
   "metadata": {},
   "source": [
    "#### We also can generalize images adding third channel dimensions (as in RGB) or from a single image to a batch of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff339006",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_t = torch.randn(2, 3, 5, 5) #shape [batch, channels, rows, columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3354d8f9",
   "metadata": {},
   "source": [
    "#### And we can eliminate channels to turn into gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2fb6850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), torch.Size([2, 5, 5]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_naive = img_t.mean(-3) # Eliminating RGB (-3 is the first, third counting from the end)\n",
    "batch_gray_naive = batch_t.mean(-3) # Eliminating RGB\n",
    "img_gray_naive.shape, batch_gray_naive.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb3e850",
   "metadata": {},
   "source": [
    "#### But now we have the weight, too. We can multiply things that are the same shape, as well as shapes where one operand is of size 1 in a given dimension. It also appends leading dimensions of size 1 automatically. \n",
    "\n",
    "#### batch_t of shape (2, 3, 5, 5) is multiplied by unsqueezed_weights of shape (3, 1, 1), resulting in a tensor of shape (2, 3, 5, 5), from which we can then sum the third dimension from the end (the three channels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91cdaee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 5, 5]), torch.Size([2, 3, 5, 5]), torch.Size([3, 1, 1]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze_(-1)\n",
    "\n",
    "img_weights = (img_t * unsqueezed_weights)\n",
    "batch_weights = (batch_t * unsqueezed_weights)\n",
    "\n",
    "img_gray_weighted = img_weights.sum(-3)\n",
    "batch_gray_weighted = batch_weights.sum(-3)\n",
    "\n",
    "batch_weights.shape, batch_t.shape, unsqueezed_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa07612",
   "metadata": {},
   "source": [
    "### Tensor value types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9b08c4",
   "metadata": {},
   "source": [
    "#### We can change the value types a tensor handles with the attribute dtype. Most common ones are 32-bit float and 64-bit int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3a4cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_points = torch.ones(10, 2, dtype = torch.double)\n",
    "short_points = torch.tensor([[1, 2], [3, 4]], dtype = torch.short)\n",
    "\n",
    "double_points = torch.zeros(10, 2).to(torch.double)\n",
    "double_points = torch.zeros(10, 2).to(dtype = torch.short)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d772a31f",
   "metadata": {},
   "source": [
    "## The Tensor API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0701f168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3,2)\n",
    "a_t = torch.transpose(a, 0, 1) # Can be also done with a_t = a.transpose(0, 1)\n",
    "\n",
    "a.shape, a_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ed9036",
   "metadata": {},
   "source": [
    "### Tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a690bf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "create = torch.ones(10,2) # Operation for creating tensors (ones, zeros... etc)\n",
    "transpose = torch.transpose(create, 0, 1) # Shape-changing functions\n",
    "# Math ops (pointwise, reduction, comparaison, spectral, other...)\n",
    "rand = torch.randn(10,2) # Random drawing from distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ab0a85",
   "metadata": {},
   "source": [
    "## Tensor storages: Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ee5b04",
   "metadata": {},
   "source": [
    "### Accessing a tensor's storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47e10bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 1.0\n",
       " 5.0\n",
       " 3.0\n",
       " 2.0\n",
       " 1.0\n",
       "[torch.FloatStorage of size 6]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points.storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ee2af6",
   "metadata": {},
   "source": [
    "#### We can also index into a storage manually as in this example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "672d94cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0, 1.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_storage = points.storage()\n",
    "\n",
    "points_storage[0], points.storage()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5271c451",
   "metadata": {},
   "source": [
    "### Understanding metadata: Offset, Stride, Shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7e19e5",
   "metadata": {},
   "source": [
    "#### The size or shape is a tuple indicating how many elements across each dimension the tensor represents. The storage offset is the index in the storage corresponding to the first element in the tensor. The stride is the number of elements in the storage that need to be skipped over to obtain the next element along each dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9c921b",
   "metadata": {},
   "source": [
    "#### We can access de 2nd index of a tensor by providing the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0027f630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "second_point = points[1]\n",
    "second_point.storage_offset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40cc8fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_point.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2baa2fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ad7046",
   "metadata": {},
   "source": [
    "#### Accessing an element i, j in a 2D tensor results in accessing the storage_offset + stride[0] * i + stride[1] * j element in the storage. The offset will usually be zero; if this tensor is a view of a storage created to hold a larger tensor, the offset might be a positive value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648faae9",
   "metadata": {},
   "source": [
    "## How subtensors work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274e7c3e",
   "metadata": {},
   "source": [
    "#### If we change the subtensor, it will affect the principal tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec031933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  1.],\n",
       "        [10.,  3.],\n",
       "        [ 2.,  1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "\n",
    "second_point = points[1]\n",
    "second_point[0] = 10.0\n",
    "\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00d0d14",
   "metadata": {},
   "source": [
    "#### If this is not our objective we can just clone the subtensor instead of linking it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2c48b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "\n",
    "second_point = points[1].clone()\n",
    "second_point[0] = 10.0\n",
    "\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7140752f",
   "metadata": {},
   "source": [
    "## Transposing tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23501e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7f99dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t = points.t()\n",
    "points_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf88178d",
   "metadata": {},
   "source": [
    "#### We can prove that both tensors have the same storage, but they differ in shape and stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db99e0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(points.storage()) == id(points_t.storage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f283fba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "182034af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2981498b",
   "metadata": {},
   "source": [
    "### Transposing multidimensional tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0950aefc",
   "metadata": {},
   "source": [
    "#### We can specify the two dimensions to transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7aafa68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_t = torch.ones(3, 4, 5)\n",
    "transpose_t = some_t.transpose(0, 2)\n",
    "some_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3bf8651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transpose_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5866ce45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_t.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9722cd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 20)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transpose_t.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaab51c",
   "metadata": {},
   "source": [
    "## Serializing and saving Tensors as Pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e4ab8e",
   "metadata": {},
   "source": [
    "### Saving weights: Two options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97c9f8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(points, '../data/p1ch3/ourpoints.t')\n",
    "\n",
    "#  with open('../data/p1ch3/ourpoints.t','wb') as f:\n",
    "#   torch.save(points, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306ee8d4",
   "metadata": {},
   "source": [
    "### Loading weights: Two options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7800a8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# points = torch.load('../data/p1ch3/ourpoints.t')\n",
    "\n",
    "#   with open('../data/p1ch3/ourpoints.t','rb') as f:\n",
    "#    points = torch.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0535e6",
   "metadata": {},
   "source": [
    "## Serializing to HDF5: Storing as NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84843317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
